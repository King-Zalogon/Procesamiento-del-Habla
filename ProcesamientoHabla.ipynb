{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe56630-145f-44fb-bf91-7c8e722f591b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Trabajo Practico n° 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1cb02-c09d-4b68-b967-01bcb79d78b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Punto 1\n",
    "Las características principales de NLTK investigue para que se usan los siguientes items.\n",
    "    \n",
    "    1. Corpus: \n",
    "    2. Tokenización:\n",
    "    3.  Stemming y Lemmatization:\n",
    "    4. Stopwords: \n",
    "    5. Clasificación: \n",
    "    6. Análisis de Sentimientos.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94ccae-1a89-41e7-8aef-ff8cca68947e",
   "metadata": {},
   "source": [
    "### Respuesta\n",
    "#### Corpus:\n",
    "##### Uso: Un corpus es una colección de textos que se utiliza para entrenar y evaluar modelos de procesamiento de lenguaje natural (PLN). NLTK proporciona acceso a varios corpus predefinidos, como el Brown Corpus y el Gutenberg Corpus, que contienen textos en inglés de diferentes géneros y épocas1.\n",
    "\n",
    "#### Tokenización:\n",
    "##### Uso: La tokenización es el proceso de dividir un texto en unidades más pequeñas, como palabras o frases. Esto es fundamental para el análisis de texto, ya que permite trabajar con fragmentos manejables de datos. NLTK ofrece herramientas para tokenizar tanto palabras como oraciones1.\n",
    "\n",
    "#### Stemming y Lemmatization:\n",
    "##### Uso:\n",
    "###### Stemming: Reduce las palabras a su raíz o forma base, eliminando sufijos y prefijos. Por ejemplo, “running” se convierte en “run”.\n",
    "###### Lemmatization: Similar al stemming, pero más preciso, ya que considera el contexto y la forma base correcta de la palabra. Por ejemplo, “better” se convierte en \"good\"2.\n",
    "\n",
    "#### Stopwords:\n",
    "##### Uso: Las stopwords son palabras comunes que se filtran antes de realizar un análisis de texto, ya que suelen no aportar mucho significado (como “y”, “el”, “de”). NLTK incluye listas de stopwords para varios idiomas2.\n",
    "\n",
    "#### Clasificación:\n",
    "##### Uso: La clasificación en NLTK se refiere a la tarea de asignar categorías a textos. Esto se puede utilizar para tareas como la clasificación de correos electrónicos (spam o no spam) o la categorización de noticias. NLTK proporciona herramientas para crear y evaluar modelos de clasificación1.\n",
    "\n",
    "#### Análisis de Sentimientos:\n",
    "##### Uso: El análisis de sentimientos es el proceso de determinar la actitud o emoción expresada en un texto. Esto puede ser útil para analizar opiniones en redes sociales, reseñas de productos, etc. NLTK permite realizar análisis de sentimientos utilizando técnicas de clasificación y lexicones de sentimientos1.\n",
    "\n",
    "1: Guía completa NLTK en Python 2: Características de NLTK: Stopwords, Stemming y Lematización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8e4ef5-9fb1-430f-946c-256f3f6b701f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Punto 2\n",
    "\n",
    "Pruebe el codigo y capture pantalla de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf7b70-352c-46ab-8727-de2dd0eea12f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### A- Tokenización de texto, realiza el siguiente ejemplo en googlecolab\n",
    "La tokenización es el proceso de dividir un texto en partes más pequeñas, como palabras o frases.\n",
    "pruebe este codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "796ca83c-780b-4248-8305-21e04ee8f397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport nltk\\nnltk.download(\\'punkt\\')\\n\\nfrom nltk.tokenize import word_tokenize, sent_tokenize\\n\\ntexto = \"Hola, este es un ejemplo simple. ¡Bienvenido al mundo de NLTK!\"\\n\\n# Tokenización por palabras\\ntokens_palabras = word_tokenize(texto)\\nprint(\"Tokenización de palabras:\", tokens_palabras)\\n\\n# Tokenización por oraciones\\ntokens_oraciones = sent_tokenize(texto)\\nprint(\"Tokenización de oraciones:\", tokens_oraciones)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "texto = \"Hola, este es un ejemplo simple. ¡Bienvenido al mundo de NLTK!\"\n",
    "\n",
    "# Tokenización por palabras\n",
    "tokens_palabras = word_tokenize(texto)\n",
    "print(\"Tokenización de palabras:\", tokens_palabras)\n",
    "\n",
    "# Tokenización por oraciones\n",
    "tokens_oraciones = sent_tokenize(texto)\n",
    "print(\"Tokenización de oraciones:\", tokens_oraciones)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf8708-ccf5-46ac-99d7-cbce89c64abe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e597bd2-6a16-4281-9787-2958e18c2c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gonza\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\gonza\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gonza\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gonza\\anaconda3\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gonza\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\gonza\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae9584ec-d94b-43d7-8e85-ef5dd8da6521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\gonza\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - nltk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2024.8.30          |   py39haa95532_0         163 KB\n",
      "    openssl-3.0.15             |       h827c3e9_0         7.8 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         7.9 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                           2024.7.4-py39haa95532_0 --> 2024.8.30-py39haa95532_0 \n",
      "  openssl                                 3.0.14-h827c3e9_0 --> 3.0.15-h827c3e9_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664c2e88-e416-4ca2-acee-8a457ae4d072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gonza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\gonza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f03659c4-ef47-4430-a30d-b64055b73b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99024647-f629-41ba-ae50-507e9d483cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Hola, este es un ejemplo simple. ¡Bienvenido al mundo de NLTK!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c91dfbae-f1f0-4c1a-b42b-e4e71146f8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenización de palabras: ['Hola', ',', 'este', 'es', 'un', 'ejemplo', 'simple', '.', '¡Bienvenido', 'al', 'mundo', 'de', 'NLTK', '!']\n"
     ]
    }
   ],
   "source": [
    "# Tokenización por palabras\n",
    "tokens_palabras = word_tokenize(texto)\n",
    "print(\"Tokenización de palabras:\", tokens_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15dd0c30-61cb-4a5a-96dc-05bf07085236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenización de oraciones: ['Hola, este es un ejemplo simple.', '¡Bienvenido al mundo de NLTK!']\n"
     ]
    }
   ],
   "source": [
    "# Tokenización por oraciones\n",
    "tokens_oraciones = sent_tokenize(texto)\n",
    "print(\"Tokenización de oraciones:\", tokens_oraciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b7419-54e3-4cff-8e69-a2004761e094",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### B-Eliminación de Stopwords\n",
    "Las stopwords son palabras comunes que no aportan mucho significado, como artículos y preposiciones. NLTK incluye un conjunto de palabras vacías para diferentes idiomas.\n",
    "pruebe el codigo y pegue los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9e30925-a74e-4540-b4f1-ce0364daee66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom nltk.corpus import stopwords\\n\\nnltk.download(\\'stopwords\\')\\n\\nstop_words = set(stopwords.words(\\'spanish\\'))\\n\\ntokens_filtrados = [word for word in tokens_palabras if word.lower() not in stop_words]\\nprint(\"Tokens después de eliminar stopwords:\", tokens_filtrados)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "tokens_filtrados = [word for word in tokens_palabras if word.lower() not in stop_words]\n",
    "print(\"Tokens después de eliminar stopwords:\", tokens_filtrados)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1ef96-28c1-4eae-a758-0bddfcef8ee2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ed5d346-966f-499f-9e4b-cf911be1cb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gonza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b27c18c0-8574-43f6-b013-cf778fe68219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens después de eliminar stopwords: ['Hola', ',', 'ejemplo', 'simple', '.', '¡Bienvenido', 'mundo', 'NLTK', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens_filtrados = [word for word in tokens_palabras if word.lower() not in stop_words]\n",
    "print(\"Tokens después de eliminar stopwords:\", tokens_filtrados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa23d11-d2b4-4c48-9810-74889e2f0ca9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### C- Stemming (Raíces de palabras), busque un ejemplo\n",
    "El stemming reduce las palabras a su raíz o forma base. NLTK incluye el PorterStemmer,para que se usa el PorterStemmer. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4e2b8-6aa1-4a3b-a8e5-c77fd3ca2797",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "452db1e8-24d0-44cf-857b-c6dd9f066f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program : program\n",
      "programs : program\n",
      "programmer : programm\n",
      "programming : program\n",
      "programmers : programm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "El PorterStemmer es uno de los algoritmos de stemming más utilizados en NLTK. \n",
    "Fue desarrollado por Martin Porter en 1980 y se utiliza para reducir las palabras a su raíz o forma base, \n",
    "eliminando sufijos y prefijos. \n",
    "Esto es útil en tareas de procesamiento de lenguaje natural, como la búsqueda de información y la minería de textos, \n",
    "ya que ayuda a reducir la redundancia y a agrupar palabras con significados similares.\n",
    "\"\"\"\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Crear una instancia del PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Lista de palabras para aplicar stemming\n",
    "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\"]\n",
    "\n",
    "# Aplicar stemming a cada palabra\n",
    "for w in words:\n",
    "    print(w, \":\", ps.stem(w))\n",
    "# En este ejemplo, todas las variaciones de la palabra “program” se reducen a la raíz \"program\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab8874-0463-46c0-aa11-9ec23a703c64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. Etiquetado de Partes del Discurso (POS Tagging) investigue para que sirve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8b951-a1bb-4a77-8671-597a18467dc5",
   "metadata": {},
   "source": [
    "El Etiquetado de Partes del Discurso (POS Tagging) es una técnica fundamental en el procesamiento del lenguaje natural (PLN). Sirve para asignar una etiqueta gramatical a cada palabra en un texto, como sustantivo, verbo, adjetivo, etc. Esto se hace según el contexto y la definición de la palabra en la oración1.\n",
    "\n",
    "¿Para qué se usa el POS Tagging?\n",
    "\n",
    "Comprensión de la estructura gramatical:\n",
    "\n",
    "Ayuda a entender cómo se relacionan las palabras en una oración, lo cual es crucial para tareas como el análisis sintáctico y la generación de lenguaje natural2.\n",
    "\n",
    "Desambiguación del sentido de las palabras:\n",
    "\n",
    "Al conocer la categoría gramatical de una palabra, es más fácil determinar su significado en un contexto específico. Por ejemplo, “banco” puede ser un sustantivo (institución financiera) o un verbo (acción de sentarse)3.\n",
    "\n",
    "Extracción de información:\n",
    "\n",
    "Facilita la identificación de entidades nombradas (como nombres de personas, lugares, organizaciones) y otros elementos clave en un texto3.\n",
    "Recuperación de información:\n",
    "\n",
    "Mejora la precisión de los motores de búsqueda y sistemas de recuperación de información al permitir búsquedas más refinadas basadas en la estructura gramatical3.\n",
    "\n",
    "Análisis de sentimientos:\n",
    "Ayuda a identificar las emociones expresadas en un texto al analizar la estructura gramatical y las palabras clave3.\n",
    "\n",
    "Sistemas de conversión de texto a voz (TTS):\n",
    "Mejora la pronunciación y entonación en los sistemas TTS al proporcionar información gramatical sobre las palabras3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d4cb0-405d-4490-8faf-d0f3576eb3da",
   "metadata": {},
   "source": [
    "#### Respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbe26aa0-0a48-4843-9d93-e0280004a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gonza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gonza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\gonza\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NLTK', 'NNP'), ('es', 'CC'), ('una', 'JJ'), ('biblioteca', 'NN'), ('poderosa', 'NN'), ('para', 'NN'), ('el', 'FW'), ('procesamiento', 'FW'), ('de', 'FW'), ('lenguaje', 'FW'), ('natural', 'JJ'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de cómo realizar POS Tagging usando NLTK en Python:\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Descargar los recursos necesarios\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Texto de ejemplo\n",
    "text = \"NLTK es una biblioteca poderosa para el procesamiento de lenguaje natural.\"\n",
    "\n",
    "# Tokenizar el texto\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Aplicar POS Tagging\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "print(pos_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce1cc7-3e48-4f7e-9e14-9476e5a02d8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5. Análisis de Sentimientos \n",
    "El análisis de sentimientos muestra la puntuación para las categorías negativa (neg), neutral (neu), positiva (pos) y un valor compound, que es una puntuación general de sentimiento. VADER que es y para que sirve VADER, busque información\n",
    "Pruebe el codigo de python\n",
    "Copiar código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df7721ba-3585-40ce-99b5-735fbeadf763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom nltk.sentiment import SentimentIntensityAnalyzer\\n\\nnltk.download(\\'vader_lexicon\\')\\n\\nsia = SentimentIntensityAnalyzer()\\noracion_sentimiento = \"Este producto es increíblemente bueno y útil.\"\\n\\nsentimiento = sia.polarity_scores(oracion_sentimiento)\\nprint(\"Análisis de sentimientos:\", sentimiento)\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "oracion_sentimiento = \"Este producto es increíblemente bueno y útil.\"\n",
    "\n",
    "sentimiento = sia.polarity_scores(oracion_sentimiento)\n",
    "print(\"Análisis de sentimientos:\", sentimiento)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a530e-771c-40c2-9737-fb04af9e655a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Respuesta\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) es una herramienta de análisis de sentimientos basada en reglas y léxico, diseñada específicamente para analizar los sentimientos expresados en textos de redes sociales1.\n",
    "\n",
    "¿Para qué sirve VADER?\n",
    "Análisis de Sentimientos en Redes Sociales:\n",
    "VADER está optimizado para captar el tono y la emoción en publicaciones de redes sociales, como tweets, comentarios y reseñas. Es capaz de manejar el lenguaje informal, las abreviaturas y los emoticonos que son comunes en estos contextos1.\n",
    "Puntuación de Sentimientos:\n",
    "VADER proporciona puntuaciones para categorías de sentimientos negativas (neg), neutrales (neu) y positivas (pos), así como un valor compuesto (compound) que representa una puntuación general de sentimiento. Este valor compuesto es una métrica agregada que varía de -1 (muy negativo) a +1 (muy positivo)1.\n",
    "Facilidad de Uso:\n",
    "Es fácil de implementar y usar en Python, lo que lo hace accesible para desarrolladores y analistas de datos que necesitan realizar análisis de sentimientos de manera rápida y eficiente1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62ae086e-8efa-4d10-9394-df232f42f897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\gonza\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de sentimientos: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "oracion_sentimiento = \"Este producto es increíblemente bueno y útil.\"\n",
    "\n",
    "sentimiento = sia.polarity_scores(oracion_sentimiento)\n",
    "print(\"Análisis de sentimientos:\", sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f2b5225-ef9c-4f09-9b5e-91112c0be43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'compound': 0.4199}\n"
     ]
    }
   ],
   "source": [
    "# Otro ejemplo que probamos\n",
    "# Crear una instancia del analizador de sentimientos\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Texto de ejemplo\n",
    "text = \"¡Me encanta usar NLTK para el procesamiento de lenguaje natural!\"\n",
    "\n",
    "# Analizar el sentimiento del texto\n",
    "sentiment = analyzer.polarity_scores(text)\n",
    "\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d2477-c163-487c-af67-ccfa86363043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
